{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "\n",
    "from PIL import Image\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import savez_compressed\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Main DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the converted metadata files for the IMDB and Wikipedia images\n",
    "photo_df = pd.read_csv('photo_info_df/All_photo_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>age_when_taken</th>\n",
       "      <th>file_path</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm124825600_...</td>\n",
       "      <td>[1072.926  161.838 1214.784  303.696]</td>\n",
       "      <td>1.459693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>71</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm3343756032...</td>\n",
       "      <td>[477.184 100.352 622.592 245.76 ]</td>\n",
       "      <td>2.543198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm577153792_...</td>\n",
       "      <td>[114.96964309 114.96964309 451.68657236 451.68...</td>\n",
       "      <td>3.455579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm946909184_...</td>\n",
       "      <td>[622.88550564 424.21750384 844.33900767 645.67...</td>\n",
       "      <td>1.872117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm980463616_...</td>\n",
       "      <td>[1013.85900236  233.88204221 1201.5861278   42...</td>\n",
       "      <td>1.158766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name         dob  gender  photo_taken  age_when_taken  \\\n",
       "0  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "1  Fred Astaire  1899-05-10     1.0         1970              71   \n",
       "2  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "3  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "4  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  image_data/imdb_data/01/nm0000001_rm124825600_...   \n",
       "1  image_data/imdb_data/01/nm0000001_rm3343756032...   \n",
       "2  image_data/imdb_data/01/nm0000001_rm577153792_...   \n",
       "3  image_data/imdb_data/01/nm0000001_rm946909184_...   \n",
       "4  image_data/imdb_data/01/nm0000001_rm980463616_...   \n",
       "\n",
       "                                       face_location  face_score  \n",
       "0              [1072.926  161.838 1214.784  303.696]    1.459693  \n",
       "1                  [477.184 100.352 622.592 245.76 ]    2.543198  \n",
       "2  [114.96964309 114.96964309 451.68657236 451.68...    3.455579  \n",
       "3  [622.88550564 424.21750384 844.33900767 645.67...    1.872117  \n",
       "4  [1013.85900236  233.88204221 1201.5861278   42...    1.158766  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(photo_df[photo_df.file_path.str.startswith('image_data/imdb_data/99/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Basic.ipynb                       \u001b[34mfred_image\u001b[m\u001b[m/\r\n",
      "EDA.ipynb                             \u001b[34mfunctioning functions\u001b[m\u001b[m/\r\n",
      "FaceNet Base Model.ipynb              \u001b[34mimage_data\u001b[m\u001b[m/\r\n",
      "FaceNet Model-Friday.ipynb            imdb_metadata_cleanup.ipynb\r\n",
      "FaceNet Model.ipynb                   \u001b[34mphoto_info_df\u001b[m\u001b[m/\r\n",
      "\u001b[34mFaceNet_Model\u001b[m\u001b[m/                        photo_metadata.csv\r\n",
      "Image To Array Notebook-Copy1.ipynb   photo_metadata_second_faces.csv\r\n",
      "Image To Array Notebook.ipynb         wiki_metadata_cleanup.ipynb\r\n",
      "README.md                             wiki_photo_metadata.csv\r\n",
      "config.py                             wiki_photo_metadata_second_faces.csv\r\n",
      "first_1000_wiki\r\n"
     ]
    }
   ],
   "source": [
    "main_image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 384199 entries, 0 to 384198\n",
      "Data columns (total 8 columns):\n",
      "name              384199 non-null object\n",
      "dob               384199 non-null object\n",
      "gender            384199 non-null float64\n",
      "photo_taken       384199 non-null int64\n",
      "age_when_taken    384199 non-null int64\n",
      "file_path         384199 non-null object\n",
      "face_location     384199 non-null object\n",
      "face_score        384199 non-null float64\n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 23.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#There are 511817 total images across 73399 individuals\n",
    "photo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_picture(filename, dimensions = (160,160), margin = 0):\n",
    "            \n",
    "    # load the image\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = asarray(image)\n",
    "    \n",
    "    #Set a margin boolean and while loop to try margin value\n",
    "    margin_error = True\n",
    "    \n",
    "    while margin_error:\n",
    "    \n",
    "        try:\n",
    "            #Crop the face further with MTCNN\n",
    "            detector = MTCNN()\n",
    "    \n",
    "            #Obtain the first detected face in the cropped face picture\n",
    "            first_detected_face = detector.detect_faces(image_array)[0]\n",
    "        \n",
    "            # get coordinates\n",
    "            x1, y1, width, height = first_detected_face['box']\n",
    "            x2, y2 = x1 + width + margin, y1 + height + margin       \n",
    "            x1 -= margin\n",
    "            y1 -= margin \n",
    "        \n",
    "            face_array = image_array[y1:y2, x1:x2]\n",
    "    \n",
    "        except:\n",
    "        \n",
    "            face_array = image_array\n",
    "        \n",
    "        try:\n",
    "            face_array_resized = Image.fromarray(face_array)\n",
    "            face_array_resized = face_array_resized.resize(dimensions)\n",
    "            \n",
    "            margin_error = False\n",
    "            break\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            if margin > 0: \n",
    "                margin -= 1\n",
    "            else:\n",
    "                face_array_resized = Image.fromarray(image_array)\n",
    "                face_array_resized = face_array_resized.resize(dimensions)\n",
    "                break\n",
    "    \n",
    "    return asarray(face_array_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = photo_df[:100].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/mtcnn/layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:27<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "test_df['photo_np'] = test_df['file_path'].progress_apply(lambda x: resize_picture(x, dimensions = (160,160), margin = 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_face(face_data):\n",
    "    \n",
    "    # plot face\n",
    "    plt.axis('off')\n",
    "    plt.imshow(face_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_face(picture1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_df['photo_np']\n",
    "y = test_df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(test_df.sample(frac=1), [int(.6*len(test_df)), int(.8*len(test_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = train['photo_np']\n",
    "trainy = train['name']\n",
    "\n",
    "validatex = validate['photo_np']\n",
    "validatey = validate['name']\n",
    "\n",
    "testx = test['photo_np']\n",
    "testy = test['name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (60, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f722b0222f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    351\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (60, 1)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu', input_shape = (160, 160, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "model.fit(trainx.values, trainy.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation For The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function is from 'Deep Learning for Computer Vision' by Jason Brownlee, Page (508)\n",
    "\n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the FaceNet model\n",
    "facenet_model = load_model('FaceNet_Model/facenet_keras.h5')\n",
    "facenet_model.load_weights('FaceNet_Model/facenet_keras_weights.h5')\n",
    "print(facenet_model.inputs)\n",
    "print(facenet_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_embedding(facenet_model, picture1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "photo_df['embeddings'] = photo_df['file_path'].progress_apply(lambda x: resize_picture(x, dimensions = (160,160), margin = 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
