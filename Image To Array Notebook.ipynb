{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import CascadeClassifier\n",
    "classifier = CascadeClassifier('cascade_models/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Main DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the converted metadata files for the images\n",
    "photo_df = pd.read_csv('photo_info_df/All_photo_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>age_when_taken</th>\n",
       "      <th>file_path</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm124825600_...</td>\n",
       "      <td>[1072.926  161.838 1214.784  303.696]</td>\n",
       "      <td>1.459693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>71</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm3343756032...</td>\n",
       "      <td>[477.184 100.352 622.592 245.76 ]</td>\n",
       "      <td>2.543198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm577153792_...</td>\n",
       "      <td>[114.96964309 114.96964309 451.68657236 451.68...</td>\n",
       "      <td>3.455579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm946909184_...</td>\n",
       "      <td>[622.88550564 424.21750384 844.33900767 645.67...</td>\n",
       "      <td>1.872117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899-05-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>69</td>\n",
       "      <td>image_data/imdb_data/01/nm0000001_rm980463616_...</td>\n",
       "      <td>[1013.85900236  233.88204221 1201.5861278   42...</td>\n",
       "      <td>1.158766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name         dob  gender  photo_taken  age_when_taken  \\\n",
       "0  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "1  Fred Astaire  1899-05-10     1.0         1970              71   \n",
       "2  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "3  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "4  Fred Astaire  1899-05-10     1.0         1968              69   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  image_data/imdb_data/01/nm0000001_rm124825600_...   \n",
       "1  image_data/imdb_data/01/nm0000001_rm3343756032...   \n",
       "2  image_data/imdb_data/01/nm0000001_rm577153792_...   \n",
       "3  image_data/imdb_data/01/nm0000001_rm946909184_...   \n",
       "4  image_data/imdb_data/01/nm0000001_rm980463616_...   \n",
       "\n",
       "                                       face_location  face_score  \n",
       "0              [1072.926  161.838 1214.784  303.696]    1.459693  \n",
       "1                  [477.184 100.352 622.592 245.76 ]    2.543198  \n",
       "2  [114.96964309 114.96964309 451.68657236 451.68...    3.455579  \n",
       "3  [622.88550564 424.21750384 844.33900767 645.67...    1.872117  \n",
       "4  [1013.85900236  233.88204221 1201.5861278   42...    1.158766  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372917 entries, 0 to 372916\n",
      "Data columns (total 8 columns):\n",
      "name              372917 non-null object\n",
      "dob               372917 non-null object\n",
      "gender            372917 non-null float64\n",
      "photo_taken       372917 non-null int64\n",
      "age_when_taken    372917 non-null int64\n",
      "file_path         372917 non-null object\n",
      "face_location     372917 non-null object\n",
      "face_score        372917 non-null float64\n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#There are 372917 total images across 53690 individuals\n",
    "photo_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_image_pixels(filename):\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    return asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo_df[photo_df['file_path'].str.contains(\"image_data/imdb_data/\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_faces(image_array):\n",
    "    \n",
    "    #Obtain the first detected face in the cropped face picture\n",
    "    faces_detected = classifier.detectMultiScale(image_array)\n",
    "    \n",
    "    #MTCNN already returns the list by sorted confidence level\n",
    "    return faces_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_picture(image_array, face_box, dimensions = (160,160), margin = 8):\n",
    "            \n",
    "    #Set a margin boolean and while loop to try margin value\n",
    "    margin_error = True\n",
    "    \n",
    "    while margin_error:\n",
    "    \n",
    "        try:\n",
    "        \n",
    "            # get coordinates\n",
    "            x1, y1, width, height = face_box\n",
    "            x2, y2 = x1 + width + margin, y1 + height + margin       \n",
    "            x1 -= margin\n",
    "            y1 -= margin \n",
    "        \n",
    "            face_array = image_array[y1:y2, x1:x2]\n",
    "    \n",
    "            face_array_resized = Image.fromarray(face_array)\n",
    "            face_array_resized = face_array_resized.resize(dimensions)\n",
    "            \n",
    "            margin_error = False\n",
    "            break\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            if margin > 0: \n",
    "                margin -= 1\n",
    "            else:\n",
    "                face_array_resized = Image.fromarray(image_array)\n",
    "                face_array_resized = face_array_resized.resize(dimensions)\n",
    "                break\n",
    "    \n",
    "    return asarray(face_array_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_resized_faces(file_path_name, dimensions = (160,160), margin = 8):\n",
    "    \n",
    "    all_image_pixels = obtain_image_pixels(file_path_name)\n",
    "    \n",
    "    all_image_faces = get_all_faces(all_image_pixels)\n",
    "    \n",
    "    face_array_list = []\n",
    "    \n",
    "    #The reason I return the entire image is because the main dataset already lists minimum\n",
    "    #detected confidence level by face, I remove certain images by this value later\n",
    "    if len(all_image_faces) == 0:\n",
    "        \n",
    "        face_array_resized = Image.fromarray(all_image_pixels)\n",
    "        face_array_resized = face_array_resized.resize(dimensions)\n",
    "        face_array_list.append(asarray(face_array_resized))\n",
    "        \n",
    "    else:\n",
    "        for i in all_image_faces:\n",
    "            face_array_list.append(resize_picture(all_image_pixels, i, dimensions, margin))\n",
    "            \n",
    "    return face_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_face(face_data, is_array = True):\n",
    "    \n",
    "    #A use case if the array is sent\n",
    "    if is_array:\n",
    "        # plot face\n",
    "        plt.axis('off')\n",
    "        plt.imshow(face_data)\n",
    "        plt.show()\n",
    "    \n",
    "    #A use case if a file path is sent\n",
    "    else:\n",
    "        # load image from file as array\n",
    "        pixels = plt.imread(face_data)\n",
    "\n",
    "        #Display image unedited\n",
    "        plt.axis('off')\n",
    "        plt.imshow(pixels)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187662\n",
      "185255\n"
     ]
    }
   ],
   "source": [
    "#A check to see if the file path exists\n",
    "file_exists = 0\n",
    "file_not_exist = 0\n",
    "\n",
    "file_not_exist_list = []\n",
    "\n",
    "for i in photo_df.file_path:\n",
    "    if path.exists(i):\n",
    "        file_exists += 1\n",
    "    else: \n",
    "        \n",
    "        file_not_exist_list.append(i)\n",
    "        file_not_exist += 1\n",
    "        \n",
    "        \n",
    "print(file_exists)\n",
    "print(file_not_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Basic.ipynb                       \u001b[34mfred_image\u001b[m\u001b[m/\r\n",
      "EDA.ipynb                             \u001b[34mfunctioning functions\u001b[m\u001b[m/\r\n",
      "FaceNet Base Model.ipynb              \u001b[34mimage_data\u001b[m\u001b[m/\r\n",
      "FaceNet Model-Friday.ipynb            imdb_metadata_cleanup.ipynb\r\n",
      "FaceNet Model.ipynb                   move_relevant_images_notebook.ipynb\r\n",
      "\u001b[34mFaceNet_Model\u001b[m\u001b[m/                        \u001b[34mphoto_info_df\u001b[m\u001b[m/\r\n",
      "Image To Array Notebook-Copy1.ipynb   photo_metadata.csv\r\n",
      "Image To Array Notebook.ipynb         photo_metadata_second_faces.csv\r\n",
      "README.md                             wiki_metadata_cleanup.ipynb\r\n",
      "\u001b[34mcascade_models\u001b[m\u001b[m/                       wiki_photo_metadata.csv\r\n",
      "config.py                             wiki_photo_metadata_second_faces.csv\r\n",
      "first_1000_wiki\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_not_exist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 368/372917 [00:16<7:08:01, 14.51it/s]"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_data/imdb_data/36/nm0000036_rm317635072_1895-10-4_1965.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-950cab8d1050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mphoto_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'face_pixels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphoto_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_all_resized_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mphoto_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'photo_info_df/photo_data_with_image_arrays_column.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# Close bar and return pandas calculation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-950cab8d1050>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mphoto_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'face_pixels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphoto_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_all_resized_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mphoto_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'photo_info_df/photo_data_with_image_arrays_column.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1306f4ce2b6b>\u001b[0m in \u001b[0;36mget_all_resized_faces\u001b[0;34m(file_path_name, dimensions, margin)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_all_resized_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mall_image_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobtain_image_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_image_pixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-617cc59070a6>\u001b[0m in \u001b[0;36mobtain_image_pixels\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobtain_image_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_data/imdb_data/36/nm0000036_rm317635072_1895-10-4_1965.jpg'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 369/372917 [00:30<7:08:00, 14.51it/s]"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "photo_df['face_pixels'] = photo_df.file_path.progress_apply(lambda x: get_all_resized_faces(x, dimensions = (160,160))[0])\n",
    "photo_df.to_csv('photo_info_df/photo_data_with_image_arrays_column.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_A = photo_df[:50000]\n",
    "photo_df_B = photo_df[50000:100000]\n",
    "photo_df_C = photo_df[100000:150000]\n",
    "photo_df_D = photo_df[150000:200000]\n",
    "photo_df_E = photo_df[200000:250000]\n",
    "photo_df_F = photo_df[250000:300000]\n",
    "photo_df_G = photo_df[300000:350000]\n",
    "photo_df_H = photo_df[350000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_A['original_image_array'] = photo_df_A['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_A.to_json('photo_info_df/photo_data_with_image_arrays_A.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_A = pd.read_json('photo_info_df/photo_data_with_image_arrays_A.json')\n",
    "photo_df_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_B['original_image_array'] = photo_df_B['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_B.to_json('photo_info_df/photo_data_with_image_arrays_B.json', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_B = pd.read_json('photo_info_df/photo_data_with_image_arrays_B.json', index = False)\n",
    "photo_df_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_C['original_image_array'] = photo_df_C['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_C.to_json('photo_info_df/photo_data_with_image_arrays_C.json', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_C = pd.read_json('photo_info_df/photo_data_with_image_arrays_C.json', index = False)\n",
    "photo_df_C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_D['original_image_array'] = photo_df_D['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_D.to_json('photo_info_df/photo_data_with_image_arrays_D.json', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_D = pd.read_json('photo_info_df/photo_data_with_image_arrays_D.json', index = False)\n",
    "photo_df_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_E['original_image_array'] = photo_df_E['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_E.to_json('photo_info_df/photo_data_with_image_arrays_E.json', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_E = pd.read_json('photo_info_df/photo_data_with_image_arrays_E.json', index = False)\n",
    "photo_df_E.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_F['original_image_array'] = photo_df_F['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_F.to_json('photo_info_df/photo_data_with_image_arrays_F.json', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_F = pd.read_json('photo_info_df/photo_data_with_image_arrays_F.json', index = False)\n",
    "photo_df_F.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_G['original_image_array'] = photo_df_G['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_G.to_json('photo_info_df/photo_data_with_image_arrays_G.json', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_G = pd.read_json('photo_info_df/photo_data_with_image_arrays_G.json', index = False)\n",
    "photo_df_G.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block of code obtains the image tensor from the image files (Part A)\n",
    "tqdm.pandas()\n",
    "photo_df_H['original_image_array'] = photo_df_H['file_path'].progress_apply(lambda x: obtain_image_array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_H.to_json('photo_info_df/photo_data_with_image_arrays_H.json', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df_H = pd.read_json('photo_info_df/photo_data_with_image_arrays_H.json', index = False)\n",
    "photo_df_H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block combines and saves the dataframes\n",
    "photo_df = pd.concat([photo_df_A, photo_df_B, photo_df_C, photo_df_D]).reset_index(drop=True)\n",
    "photo_df.to_csv('photo_info_df/photo_data_with_image_arrays.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "photo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df.file_path[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_picture(filename, dimensions = (160,160), margin = 0):\n",
    "            \n",
    "    # load the image\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    image_array = asarray(image)\n",
    "    \n",
    "    \n",
    "    #Set a margin boolean and while loop to try margin value\n",
    "    margin_error = True\n",
    "    \n",
    "    while margin_error:\n",
    "    \n",
    "        try:\n",
    "            #Crop the face further with MTCNN\n",
    "            detector = MTCNN()\n",
    "    \n",
    "            #Obtain the first detected face in the cropped face picture\n",
    "            first_detected_face = detector.detect_faces(image_array)[0]\n",
    "        \n",
    "            # get coordinates\n",
    "            x1, y1, width, height = first_detected_face['box']\n",
    "            x2, y2 = x1 + width + margin, y1 + height + margin       \n",
    "            x1 -= margin\n",
    "            y1 -= margin \n",
    "        \n",
    "            face_array = image_array[y1:y2, x1:x2]\n",
    "    \n",
    "        except:\n",
    "        \n",
    "            face_array = image_array\n",
    "        \n",
    "        try:\n",
    "            face_array_resized = Image.fromarray(face_array)\n",
    "            face_array_resized = face_array_resized.resize(dimensions)\n",
    "            \n",
    "            margin_error = False\n",
    "            break\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            if margin > 0: \n",
    "                margin -= 1\n",
    "            else:\n",
    "                face_array_resized = Image.fromarray(image_array)\n",
    "                face_array_resized = face_array_resized.resize(dimensions)\n",
    "                break\n",
    "    \n",
    "    return asarray(face_array_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = resize_picture('image_data/imdb_data/02/nm0000002_rm1363385088_1924-9-16_2004.jpg', dimensions = (160,160), margin = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture1 = resize_picture(photo_df.file_path[0], dimensions = (160,160), margin = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_face(face_data):\n",
    "    \n",
    "    # plot face\n",
    "    plt.axis('off')\n",
    "    plt.imshow(face_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_face(picture1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo_df[photo_df['file_path'].str.contains(\"961400_1953-02-05_2011\", case=False)]\n",
    "#photo_df[photo_df['face_score']<=1]\n",
    "photo_df.file_path[photo_df['face_score'] == photo_df['face_score'].max()]\n",
    "photo_df.file_path[54153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = photo_df[:100].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm.pandas()\n",
    "#test['original_image_array'] = test['file_path'].progress_apply(lambda x: resize_picture(x, dimensions = (160,160), margin = 8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "test['original_image_array'] = test['file_path'].progress_apply(lambda x: obtain_image_array(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "test['fn_resized_array'] = test['original_image_array'].progress_apply(lambda x: resize_picture(x, dimensions = (160,160), margin = 8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fn_resized_array[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation For The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function is from 'Deep Learning for Computer Vision' by Jason Brownlee, Page (508)\n",
    "\n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the FaceNet model\n",
    "facenet_model = load_model('FaceNet_Model/facenet_keras.h5')\n",
    "facenet_model.load_weights('FaceNet_Model/facenet_keras_weights.h5')\n",
    "print(facenet_model.inputs)\n",
    "print(facenet_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_embedding(facenet_model, picture1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
